---
layout: post
title: 统一网关设计
categories: JVM
description: 统一网关设计
---

### 背景概述
> 系统有简单的也有复杂的，说是简单其实架构设计上，单点系统也有复杂的业务和模块划分，复杂的系统除了表现在业务，更主要的是在整个系统网络层面和技术层面的设计，比如说从开发框架、模块子系统划分、统一网关、日志追踪监控、CI自动化部署、自动化扩容等等方面来设计。

> 最近也是在思考现如今模块子系统和微服务的技术栈越来越多，在此基础上如何设计实现一个统一网关，我觉得就应该从设计目标、可调用资源、当前和未来满足的业务量的本身出发，利弊权衡，选择自己合适的网关

### 网络部署架构

#### 网关职责
核心功能：服务路由、负载均衡、安全校验
扩展功能：流量监控报警、熔断、超时管控、服务限流和降级、日志、服务隔离

#### 设计目标
1. Java语言实现
2. 横向扩展，高性能
3. 避免单个服务故障导致整个网关不可用，做到服务隔离，流量限制
4. 后台可动态调整配置自动生效

### 技术选型
| 开源解决方案              | 优点                                       | 缺点                                   |
| ------------------- | ---------------------------------------- | ------------------------------------ |
| Nginx+Lua           | 轻量级解决方案，利用Lua脚本可实现高性能简易API网关，问题解答相关的资料难找 | 开发和维护难度大，定制化功能较弱                     |
| Netflix/Zuul        | Spring Cloud完整解决方案中推荐Gateway解决方案，社区论坛活跃，问题易于解决，接入层对REST协议友好，可快速搭建简单易用 | 实属Netflix全家桶中的一环，集成依赖大，组件多且复杂度高      |
| Netty自研             | 高性能网络框架，底层JAVA实现，市面上很多实现开源网关方案，可定制化开发，开发问题易于定位和解决 | 需投入相对较多的研发资源                         |
| Kong/kong           | 高性能网关服务，底层用的是nginx接收处理请求                 | 此项目基于nginx二次开发的网关，前期需投入过大人力成本研究，起点较高 |
| TykTechnologies/tky | 基于go实现                                   |                                      |
| openresty           | 底层同Kong                                  |                                      |
| ...                 |                                          |                                      |


### 架构设计

#### 开发框架Spring Boot + Netty

Spring Boot：选它主要考虑到框架的熟悉程度和后续人员维护难以程度，Spring的优势易于加载扩展功能组件

Netty：主要实现网关反向代理和路由转发功能

#### 各功能实现思路

服务路由：网关节点在内存中负责维护各自的路由表，且保证和后台路由的数据一致，可选择zk和mq来实现路由表的同步。网关接收到请求后，自定义Channel-ChannelHandlerAdapter负责读取路由表、安全校验、日志输入，然后利用HttpClient同步多线程转发

负载均衡：有两种思路：
a. 网关不处理此项功能，将其移交给下游ng或者slb来实现，也算是偷个懒
b. 网关自行实现负载均衡服务映射的主机列表，主要策略有：轮询和hash映射

安全校验：上边的服务路由有提到，在ChannelHandler中channelRead操作中可设计安全校验机制，主要对于输入参数的校验，比如：现在前后端分离的架构中对token无状态票据进行验证和颁发

流程监控告警、降级：可在ChannelHandler中的connect和disconnect前后添加不同维度监控，比如：网关节点、服务、用户等等维度

熔断、故障隔离：主要可参考Hystrix的实践方案，服务调用超时后自动熔断，过段时间可自动恢复

超时管控：可利用HttpClient客户端进行实现，设置connet timeout和read timeout，一旦发生此类异常立即释放资源并响应，失败次数超限后引入故障隔离
